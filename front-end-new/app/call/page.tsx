'use client';

import { useState, useEffect, useRef } from 'react';
import io from 'socket.io-client';
import CallInterface from '@/components/CallInterface';
import CallSetup from '@/components/CallSetup';

interface CallState {
  isInCall: boolean;
  isConnected: boolean;
  isMuted: boolean;
  isVideoEnabled: boolean;
  callDuration: number;
  fraudResult?: {
    classification: 'Safe' | 'Fraud Detected';
    confidence: number;
    timestamp: Date;
  };
}

export default function CallPage() {
  const [socket, setSocket] = useState<any>(null);
  const [callState, setCallState] = useState<CallState>({
    isInCall: false,
    isConnected: false,
    isMuted: false,
    isVideoEnabled: true,
    callDuration: 0,
  });
  const [username, setUsername] = useState<string>('');
  const [showSetup, setShowSetup] = useState(true);
  const [remoteUser, setRemoteUser] = useState<string>('');
  const [callType, setCallType] = useState<'audio' | 'video'>('audio');
  const [availableUsers, setAvailableUsers] = useState<string[]>([]);
  
  const localVideoRef = useRef<HTMLVideoElement>(null);
  const remoteVideoRef = useRef<HTMLVideoElement>(null);
  const localStreamRef = useRef<MediaStream | null>(null);
  const peerConnectionRef = useRef<RTCPeerConnection | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const callTimerRef = useRef<ReturnType<typeof setInterval> | null>(null);

  useEffect(() => {
    // Initialize WebSocket connection
    const newSocket = io(process.env.NEXT_PUBLIC_SOCKET_URL || 'http://localhost:3001', {
      transports: ['websocket'],
    });



    newSocket.on('disconnect', () => {
      setCallState(prev => ({ ...prev, isConnected: false }));
      console.log('âŒ Disconnected from signaling server');
      
      // Auto-reconnect after 3 seconds
      setTimeout(() => {
        if (!socket?.connected) {
          console.log('ðŸ”„ Attempting to reconnect...');
          newSocket.connect();
        }
      }, 3000);
    });

    newSocket.on('connect_error', (error: any) => {
      console.error('âŒ Connection error:', error);
      setCallState(prev => ({ ...prev, isConnected: false }));
    });

    newSocket.on('reconnect', () => {
      console.log('âœ… Reconnected to signaling server');
      setCallState(prev => ({ ...prev, isConnected: true }));
    });

    // Signaling events
    newSocket.on('offer', handleOffer);
    newSocket.on('answer', handleAnswer);
    newSocket.on('iceCandidate', handleIceCandidate);
    newSocket.on('userJoined', handleUserJoined);
    newSocket.on('userLeft', handleUserLeft);
    newSocket.on('callRequest', handleCallRequest);
    newSocket.on('callAccepted', handleCallAccepted);
    newSocket.on('callRejected', handleCallRejected);
    newSocket.on('callEnded', handleCallEnded);

    // Audio fraud detection results
    newSocket.on('fraudResult', (data: { classification: string; confidence: number }) => {
      setCallState(prev => ({
        ...prev,
        fraudResult: {
          classification: data.classification as 'Safe' | 'Fraud Detected',
          confidence: data.confidence,
          timestamp: new Date(),
        }
      }));
    });

    // User list updates
    newSocket.on('userList', (users: string[]) => {
      const filteredUsers = users.filter(user => user !== username && user && user.trim() !== '');
      setAvailableUsers(filteredUsers);
    });

    // Request user list when connected
    newSocket.on('connect', () => {
      setCallState(prev => ({ ...prev, isConnected: true }));
      console.log('âœ… Connected to signaling server');
      // Request current user list
      newSocket.emit('getUserList');
    });

    // Handle disconnection
    newSocket.on('disconnect', () => {
      setCallState(prev => ({ ...prev, isConnected: false }));
      console.log('âŒ Disconnected from signaling server');
    });

    // Handle connection errors
    newSocket.on('connect_error', (error: any) => {
      console.error('âŒ Connection error:', error);
      setCallState(prev => ({ ...prev, isConnected: false }));
    });

    setSocket(newSocket);

    return () => {
      newSocket.close();
    };
  }, []);

  useEffect(() => {
    // Call timer
    if (callState.isInCall) {
      callTimerRef.current = setInterval(() => {
        setCallState(prev => ({
          ...prev,
          callDuration: prev.callDuration + 1
        }));
      }, 1000);
    } else {
      if (callTimerRef.current) {
        clearInterval(callTimerRef.current);
      }
    }

    return () => {
      if (callTimerRef.current) {
        clearInterval(callTimerRef.current);
      }
    };
  }, [callState.isInCall]);

  // Monitor socket connection state
  useEffect(() => {
    if (socket) {
      console.log('ðŸ” Socket connection state changed:', socket.connected);
      setCallState(prev => ({ ...prev, isConnected: socket.connected }));
    }
  }, [socket]);

  const handleUserJoined = (data: { username: string }) => {
    console.log(`${data.username} joined the call room`);
    // Request updated user list
    if (socket) {
      socket.emit('getUserList');
    }
  };

  const handleUserLeft = (data: { username: string }) => {
    console.log(`${data.username} left the call room`);
    if (data.username === remoteUser) {
      endCall();
    }
    // Request updated user list
    if (socket) {
      socket.emit('getUserList');
    }
  };

  const handleCallRequest = async (data: { from: string; type: 'audio' | 'video' }) => {
    console.log('ðŸ“ž Call request from:', data.from, 'Type:', data.type);
    const accepted = window.confirm(`${data.from} wants to start a ${data.type} call. Accept?`);
    if (accepted) {
      console.log('âœ… Call accepted');
      setRemoteUser(data.from);
      setCallType(data.type);
      
      // Get current socket instance directly
      const currentSocket = socket;
      console.log('ðŸ” Current socket state:', currentSocket ? 'Available' : 'Not available');
      console.log('ðŸ” Socket connected:', currentSocket?.connected);
      
      // Send acceptance notification immediately if socket is available
      if (currentSocket && currentSocket.connected) {
        currentSocket.emit('callAccepted', { to: data.from });
        console.log('ðŸ“¤ Call accepted notification sent');
        
        // Initialize call after sending acceptance
        console.log('ðŸ”§ Starting call initialization...');
        await initializeCall();
      } else {
        console.error('âŒ Socket not available or not connected');
        console.log('ðŸ” Socket object:', currentSocket);
        console.log('ðŸ” Socket connected state:', currentSocket?.connected);
        
        // Try to reconnect and retry
        console.log('ðŸ”„ Attempting to reconnect...');
        const socketUrl = process.env.NEXT_PUBLIC_SOCKET_URL || 'http://localhost:3000';
        const newSocket = io(socketUrl);
        
        newSocket.on('connect', async () => {
          console.log('âœ… Reconnected to signaling server');
          newSocket.emit('callAccepted', { to: data.from });
          console.log('ðŸ“¤ Call accepted notification sent after reconnect');
          
          // Set the new socket and initialize call
          setSocket(newSocket);
          await initializeCall();
        });
        
        newSocket.on('connect_error', (error: any) => {
          console.error('âŒ Reconnection failed:', error);
          alert('Connection lost. Please refresh the page and try again.');
        });
      }
    } else {
      console.log('âŒ Call rejected');
      
      // Get current socket instance directly
      const currentSocket = socket;
      
      if (currentSocket && currentSocket.connected) {
        currentSocket.emit('callRejected', { to: data.from });
        console.log('ðŸ“¤ Call rejected notification sent');
      } else {
        console.log('âš ï¸ Socket not available for rejection, but call was already rejected by user');
      }
    }
  };

  const handleCallAccepted = (data: { from: string }) => {
    console.log('âœ… Audio call accepted by:', data.from);
    setRemoteUser(data.from);
    setCallState(prev => ({ ...prev, isInCall: true }));
    setShowSetup(false);
    console.log('ðŸŽµ Waiting for audio offer from:', data.from);
  };

  const handleCallRejected = (data: { from: string }) => {
    console.log('âŒ Call rejected by:', data.from);
    alert(`${data.from} rejected your call`);
    endCall();
  };

  const handleCallEnded = (data: { from: string }) => {
    console.log('ðŸ“ž Call ended by:', data.from);
    endCall();
  };

  const initializeCall = async () => {
    try {
      console.log('ðŸ”§ Initializing audio call...');
      
      // Get current socket instance directly
      const currentSocket = socket;
      console.log('ðŸ” Current socket state:', currentSocket ? 'Available' : 'Not available');
      console.log('ðŸ” Socket connected:', currentSocket?.connected);
      
      if (!currentSocket || !currentSocket.connected) {
        console.error('âŒ Socket not available or not connected');
        console.log('ðŸ” Socket object:', currentSocket);
        console.log('ðŸ” Socket connected state:', currentSocket?.connected);
        alert('Connection lost. Please refresh the page and try again.');
        return;
      }

      console.log('âœ… Socket connection confirmed');

      // Get user media - audio only
      console.log('ðŸ“± Getting audio media...');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: false,
        audio: true
      });

      console.log('âœ… Audio stream obtained');
      localStreamRef.current = stream;
      
      // Create peer connection
      console.log('ðŸ”— Creating peer connection...');
      const peerConnection = new RTCPeerConnection({
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          { urls: 'stun:stun1.l.google.com:19302' }
        ]
      });

      peerConnectionRef.current = peerConnection;

      // Add local audio track only
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        peerConnection.addTrack(audioTrack, stream);
        console.log('âœ… Audio track added to peer connection');
      }

      // Handle incoming tracks
      peerConnection.ontrack = (event) => {
        console.log('ðŸŽµ Remote audio stream received during initialization');
        if (remoteVideoRef.current) {
          remoteVideoRef.current.srcObject = event.streams[0];
        }
      };

      // Handle ICE candidates
      peerConnection.onicecandidate = (event) => {
        if (event.candidate && currentSocket && currentSocket.connected) {
          console.log('ðŸ§Š Sending ICE candidate during initialization');
          currentSocket.emit('iceCandidate', {
            to: remoteUser,
            candidate: event.candidate
          });
        }
      };

      // Handle connection state changes
      peerConnection.onconnectionstatechange = () => {
        console.log('ðŸ”— Connection state during initialization:', peerConnection.connectionState);
        if (peerConnection.connectionState === 'connected') {
          console.log('âœ… WebRTC audio connection established');
          setCallState(prev => ({ ...prev, isInCall: true }));
        } else if (peerConnection.connectionState === 'failed') {
          console.error('âŒ WebRTC connection failed during initialization');
          endCall();
        }
      };

      // Start audio processing for fraud detection
      startAudioProcessing(stream);

      setShowSetup(false);
      
      console.log('âœ… Audio call initialization completed');

    } catch (error) {
      console.error('âŒ Error initializing audio call:', error);
      alert('Failed to access microphone');
      endCall();
    }
  };

  const startAudioProcessing = (stream: MediaStream) => {
    try {
      // Check if MediaRecorder is supported
      if (!window.MediaRecorder) {
        console.warn('MediaRecorder not supported, skipping audio recording');
        return;
      }

      // Create audio context
      const audioContext = new AudioContext();
      audioContextRef.current = audioContext;

      // Check supported MIME types
      const supportedTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/mp4',
        'audio/ogg;codecs=opus',
        'audio/wav'
      ];
      
      let selectedType = '';
      for (const type of supportedTypes) {
        if (MediaRecorder.isTypeSupported(type)) {
          selectedType = type;
          break;
        }
      }

      if (!selectedType) {
        console.warn('No supported audio MIME type found, skipping audio recording');
        return;
      }

      // Create media recorder for audio chunks
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: selectedType
      });
      mediaRecorderRef.current = mediaRecorder;

      // Process audio chunks every 3 seconds
      let audioChunks: Blob[] = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunks, { type: selectedType });
        sendAudioToServer(audioBlob);
        audioChunks = [];
      };

      // Start recording in 3-second intervals
      const startRecording = () => {
        try {
          if (mediaRecorder.state === 'inactive') {
            mediaRecorder.start();
            setTimeout(() => {
              if (mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                startRecording(); // Continue recording
              }
            }, 3000);
          }
        } catch (error) {
          console.error('Error starting media recorder:', error);
        }
      };

      startRecording();

    } catch (error) {
      console.error('Error starting audio processing:', error);
      // Fallback: simulate audio processing for demo
      console.log('Using fallback audio processing simulation');
      setInterval(() => {
        if (callState.isInCall && socket) {
          // Simulate fraud detection result
          const mockResult = {
            classification: Math.random() > 0.7 ? 'Fraud Detected' : 'Safe',
            confidence: Math.random()
          };
          setCallState(prev => ({
            ...prev,
            fraudResult: {
              classification: mockResult.classification as 'Safe' | 'Fraud Detected',
              confidence: mockResult.confidence,
              timestamp: new Date(),
            }
          }));
        }
      }, 5000); // Every 5 seconds
    }
  };

  const sendAudioToServer = (audioBlob: Blob) => {
    if (socket && callState.isInCall) {
      // Convert blob to base64
      const reader = new FileReader();
      reader.onload = () => {
        const base64Audio = reader.result as string;
        if (socket) {
          socket.emit('audioChunk', {
            audio: base64Audio,
            timestamp: new Date().toISOString()
          });
        }
      };
      reader.readAsDataURL(audioBlob);
    }
  };

  const handleOffer = async (data: { from: string; offer: RTCSessionDescriptionInit }) => {
    try {
      console.log('ðŸ“¥ Received audio offer from:', data.from);
      
      // Get current socket instance directly
      const currentSocket = socket;
      console.log('ðŸ” Current socket state in handleOffer:', currentSocket ? 'Available' : 'Not available');
      console.log('ðŸ” Socket connected in handleOffer:', currentSocket?.connected);
      
      if (!currentSocket || !currentSocket.connected) {
        console.error('âŒ Socket not available or not connected when handling offer');
        return;
      }

      // Set call state
      setRemoteUser(data.from);
      setCallState(prev => ({ ...prev, isInCall: true }));
      setShowSetup(false);

      const peerConnection = new RTCPeerConnection({
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          { urls: 'stun:stun1.l.google.com:19302' }
        ]
      });

      peerConnectionRef.current = peerConnection;

      // Add local audio track if available
      if (localStreamRef.current) {
        const audioTrack = localStreamRef.current.getAudioTracks()[0];
        if (audioTrack) {
          peerConnection.addTrack(audioTrack, localStreamRef.current);
          console.log('âœ… Local audio track added to peer connection');
        }
      }

      // Handle incoming tracks
      peerConnection.ontrack = (event) => {
        console.log('ðŸŽµ Remote audio stream received from offer');
        if (remoteVideoRef.current) {
          remoteVideoRef.current.srcObject = event.streams[0];
        }
      };

      // Handle ICE candidates
      peerConnection.onicecandidate = (event) => {
        if (event.candidate && currentSocket && currentSocket.connected) {
          console.log('ðŸ§Š Sending ICE candidate from offer');
          currentSocket.emit('iceCandidate', {
            to: data.from,
            candidate: event.candidate
          });
        }
      };

      // Handle connection state changes
      peerConnection.onconnectionstatechange = () => {
        console.log('ðŸ”— Connection state from offer:', peerConnection.connectionState);
        if (peerConnection.connectionState === 'connected') {
          console.log('âœ… WebRTC audio connection established from offer');
        } else if (peerConnection.connectionState === 'failed') {
          console.error('âŒ WebRTC connection failed from offer');
          endCall();
        }
      };

      console.log('ðŸ“¤ Setting remote description and creating answer...');
      
      // Set remote description and create answer
      await peerConnection.setRemoteDescription(new RTCSessionDescription(data.offer));
      const answer = await peerConnection.createAnswer();
      await peerConnection.setLocalDescription(answer);

      if (currentSocket && currentSocket.connected) {
        currentSocket.emit('answer', {
          to: data.from,
          answer: answer
        });
        console.log('ðŸ“¤ Answer sent to:', data.from);
      } else {
        console.error('âŒ Socket not available or not connected when sending answer');
        endCall();
      }

    } catch (error) {
      console.error('âŒ Error handling audio offer:', error);
      endCall();
    }
  };

  const handleAnswer = async (data: { from: string; answer: RTCSessionDescriptionInit }) => {
    try {
      console.log('ðŸ“¥ Received answer from:', data.from);
      if (peerConnectionRef.current) {
        await peerConnectionRef.current.setRemoteDescription(new RTCSessionDescription(data.answer));
        console.log('âœ… Remote description set from answer');
      }
    } catch (error) {
      console.error('âŒ Error handling answer:', error);
    }
  };

  const handleIceCandidate = async (data: { from: string; candidate: RTCIceCandidateInit }) => {
    try {
      console.log('ðŸ§Š Received ICE candidate from:', data.from);
      if (peerConnectionRef.current) {
        await peerConnectionRef.current.addIceCandidate(new RTCIceCandidate(data.candidate));
        console.log('âœ… ICE candidate added');
      }
    } catch (error) {
      console.error('âŒ Error handling ICE candidate:', error);
    }
  };

  const initiateCall = async (targetUser: string, type: 'audio' | 'video') => {
    try {
      console.log('ðŸš€ Initiating audio call to:', targetUser);
      
      // Get current socket instance directly
      const currentSocket = socket;
      console.log('ðŸ” Current socket state:', currentSocket ? 'Available' : 'Not available');
      console.log('ðŸ” Socket connected:', currentSocket?.connected);
      
      if (!currentSocket || !currentSocket.connected) {
        console.error('âŒ Socket not available or not connected');
        console.log('ðŸ” Socket object:', currentSocket);
        console.log('ðŸ” Socket connected state:', currentSocket?.connected);
        alert('Connection lost. Please refresh the page and try again.');
        return;
      }

      console.log('âœ… Socket connection confirmed');

      // Prevent self-calling
      if (targetUser === username) {
        alert('You cannot call yourself');
        return;
      }

      // Send call request first
      console.log('ðŸ“ž Sending audio call request...');
      socket.emit('callRequest', {
        to: targetUser,
        type: 'audio'
      });
      console.log('ðŸ“¤ Audio call request sent to:', targetUser);

      // Set call state
      setRemoteUser(targetUser);
      setCallType('audio');
      
      console.log('ðŸ“± Getting audio media...');
      
      // Get user media - audio only
      const stream = await navigator.mediaDevices.getUserMedia({
        video: false,
        audio: true
      });

      console.log('âœ… Audio stream obtained');
      localStreamRef.current = stream;

      console.log('ðŸ”— Creating peer connection...');
      
      // Create peer connection
      const peerConnection = new RTCPeerConnection({
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          { urls: 'stun:stun1.l.google.com:19302' }
        ]
      });

      peerConnectionRef.current = peerConnection;

      // Add local audio track only
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        peerConnection.addTrack(audioTrack, stream);
        console.log('âœ… Audio track added to peer connection');
      }

      // Handle incoming tracks
      peerConnection.ontrack = (event) => {
        console.log('ðŸŽµ Remote audio stream received');
        if (remoteVideoRef.current) {
          remoteVideoRef.current.srcObject = event.streams[0];
        }
      };

      // Handle ICE candidates
      peerConnection.onicecandidate = (event) => {
        if (event.candidate && socket) {
          console.log('ðŸ§Š Sending ICE candidate');
          socket.emit('iceCandidate', {
            to: targetUser,
            candidate: event.candidate
          });
        }
      };

      // Handle connection state changes
      peerConnection.onconnectionstatechange = () => {
        console.log('ðŸ”— Connection state:', peerConnection.connectionState);
        if (peerConnection.connectionState === 'connected') {
          console.log('âœ… WebRTC audio connection established');
        } else if (peerConnection.connectionState === 'failed') {
          console.error('âŒ WebRTC connection failed');
          endCall();
        }
      };

      // Start audio processing
      startAudioProcessing(stream);
      
      console.log('âœ… Audio call initiation completed - waiting for acceptance');

    } catch (error) {
      console.error('âŒ Error initiating audio call:', error);
      alert('Failed to access microphone or start call');
      endCall();
    }
  };

  const endCall = () => {
    console.log('ðŸ“ž Ending call...');
    
    // Stop all tracks
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('ðŸ›‘ Stopped track:', track.kind);
      });
    }

    // Close peer connection
    if (peerConnectionRef.current) {
      peerConnectionRef.current.close();
      console.log('ðŸ”— Peer connection closed');
    }

    // Stop media recorder
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
      console.log('ðŸŽ™ï¸ Media recorder stopped');
    }

    // Close audio context
    if (audioContextRef.current) {
      audioContextRef.current.close();
      console.log('ðŸŽµ Audio context closed');
    }

    // Clear timer
    if (callTimerRef.current) {
      clearInterval(callTimerRef.current);
      console.log('â±ï¸ Call timer cleared');
    }

    // Reset call state but keep socket connection
    setCallState(prev => ({
      ...prev,
      isInCall: false,
      isMuted: false,
      isVideoEnabled: true,
      callDuration: 0,
    }));
    
    setShowSetup(true);
    setRemoteUser('');

    // Notify server
    if (socket && remoteUser) {
      socket.emit('endCall', { to: remoteUser });
      console.log('ðŸ“¤ End call notification sent');
    }

    // Clear video elements
    if (localVideoRef.current) {
      localVideoRef.current.srcObject = null;
    }
    if (remoteVideoRef.current) {
      remoteVideoRef.current.srcObject = null;
    }
    
    console.log('âœ… Call ended successfully');
  };

  const toggleMute = () => {
    if (localStreamRef.current) {
      const audioTrack = localStreamRef.current.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !audioTrack.enabled;
        setCallState(prev => ({ ...prev, isMuted: !prev.isMuted }));
      }
    }
  };

  const toggleVideo = () => {
    if (localStreamRef.current) {
      const videoTrack = localStreamRef.current.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.enabled = !videoTrack.enabled;
        setCallState(prev => ({ ...prev, isVideoEnabled: !prev.isVideoEnabled }));
      }
    }
  };

  const handleJoinCall = (user: string) => {
    setUsername(user);
    setShowSetup(false);
    if (socket) {
      socket.emit('joinCallRoom', { username: user, room: 'call' });
      // Request user list after joining
      setTimeout(() => {
        socket.emit('getUserList');
      }, 1000);
    }
  };

  if (showSetup) {
    return <CallSetup onJoin={handleJoinCall} />;
  }

  return (
    <CallInterface
      callState={callState}
      username={username}
      remoteUser={remoteUser}
      callType={callType}
      localVideoRef={localVideoRef}
      remoteVideoRef={remoteVideoRef}
      onInitiateCall={initiateCall}
      onEndCall={endCall}
      onToggleMute={toggleMute}
      onToggleVideo={toggleVideo}
      isConnected={callState.isConnected}
      availableUsers={availableUsers}
    />
  );
}